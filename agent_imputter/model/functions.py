# AUTOGENERATED! DO NOT EDIT! File to edit: ../../nbs/Model/01_model.ipynb.

# %% auto 0
__all__ = ['get_embedding_tensor_for_game', 'preprocess_data', 'split_sequences', 'get_train_test_split', 'series_data']

# %% ../../nbs/Model/01_model.ipynb 3
import itertools
import math
import os
from pathlib import Path
from typing import Callable, List, Optional, Tuple

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, RobustScaler
from sklearn import preprocessing

import torch
from torch.utils.data import DataLoader, Dataset

import wandb
from pytorch_lightning.loggers import WandbLogger

import pytorch_lightning as pl
from pytorch_lightning.callbacks import ModelCheckpoint
from pytorch_lightning.callbacks import LearningRateFinder
from .agent_imputer import AgentImputerLightning

# %% ../../nbs/Model/01_model.ipynb 9
def get_embedding_tensor_for_game(categories, idx):
    "compute embeddings of categorical features"

    def get_embedding(category_vec, idx):
        "compte embedding of one feature"
        num_classes = len(category_vec.unique())
        emb_size = math.floor(math.sqrt(num_classes))
        le = preprocessing.LabelEncoder()
        le.fit(category_vec.iloc[idx])
        cat = torch.tensor(
            np.array(le.transform(category_vec)).reshape(len(category_vec), 1)
        ).to(torch.int64)
        return cat

    cats = torch.tensor([])
    for cat in categories:
        new_cat = get_embedding(categories[cat], idx)
        cats = torch.cat((cats, new_cat), axis=1)
    return cats

# %% ../../nbs/Model/01_model.ipynb 12
def preprocess_data(
    input_data: pd.DataFrame(),
) -> Tuple:
    """"""
    scaler = MinMaxScaler(feature_range=(0, 1))
    time_scaler = MinMaxScaler(feature_range=(0, 1))

    emb_cats = get_embedding_tensor_for_game(
        input_data[
            ["position", "event_type", "team_on_ball", "player_on_ball", "goal_diff"]
        ],
        input_data.index,
    )
    scaler.fit(
        input_data[
            [
                "ballx",
                "prev_player_x",
                "next_player_x",
                "bally",
                "prev_player_y",
                "next_player_y",
                "av_player_x",
                "av_player_y",
            ]
        ]
    )
    time_scaler.fit(
        input_data[["time_since_last_pred", "prev_player_time", "next_player_time"]]
    )

    input_data_normalized = scaler.transform(
        input_data[
            [
                "ballx",
                "prev_player_x",
                "next_player_x",
                "bally",
                "prev_player_y",
                "next_player_y",
                "av_player_x",
                "av_player_y",
            ]
        ]
    )
    input_data_time = time_scaler.transform(
        input_data[["time_since_last_pred", "prev_player_time", "next_player_time"]]
    )

    input_data_normalized = np.concatenate(
        (input_data_normalized, input_data_time), axis=1
    )
    input_data_normalized = torch.cat(
        (torch.tensor(input_data_normalized), emb_cats), 1
    )

    label_data = torch.tensor(features_df[["label_x", "label_y"]].values)
    scaler.fit(label_data)
    label_data_normalized = scaler.transform(label_data)

    return input_data_normalized, label_data_normalized, scaler

# %% ../../nbs/Model/01_model.ipynb 16
def split_sequences(
    sorted_whole_input_df: pd.DataFrame(),
    input_data_normalized: torch.tensor,
    label_data_normalized: torch.tensor,
    n_steps_in: int,
    n_steps_out: int,
):
    "Gets sequences of the previous and next x values for input data"

    time_scaler = RobustScaler()
    timestamps = torch.tensor(
        time_scaler.fit_transform(
            np.array(sorted_whole_input_df["event_time"]).reshape(-1, 1)
        )
    ).reshape(-1)

    # Define the number of previous and next tensors to include
    num_prev_tensors = n_steps_in
    num_next_tensors = n_steps_out

    # Create a list to store the resulting tensors
    X = []
    y = []
    ts = []
    for i in range(0, int(len(sorted_whole_input_df) / 22)):
        prev_indices = range(max(i - num_prev_tensors, 0), i)
        next_indices = range(
            i + 1, min(i + num_next_tensors + 1, int(len(sorted_whole_input_df) / 22))
        )
        idx = []

        if len(prev_indices) == 0:
            idx.extend([i, i, i])
        elif len(prev_indices) == 1:
            idx.extend([i - 1, i - 1, i])
        else:
            idx.extend([i - 2, i - 1, i])

        if len(next_indices) == 0:
            idx.extend([i, i])
        elif len(next_indices) == 1:
            idx.extend([i + 1, i + 1])
        else:
            idx.extend([i + 1, i + 2])

        l_x = []
        l_ts = []
        for j in idx:
            eve_df = sorted_whole_input_df[sorted_whole_input_df["event_num"] == j]
            l_x.append(input_data_normalized[eve_df.index[0] : eve_df.index[-1] + 1])
            l_ts.append(timestamps[eve_df.index[0] : eve_df.index[-1] + 1])

        # concatenate the tensors along a new dimension
        input_result_tensor = torch.stack(l_x, dim=1)
        ts_result_tensor = torch.stack(l_ts, dim=1)

        # convert to list of 22 tensors of shape (5, 16)
        input_tensor_list = [tensor.squeeze(0) for tensor in input_result_tensor]
        ts_tensor_list = [tensor.squeeze() for tensor in ts_result_tensor]
        ts_tensor_list = [
            torch.abs(ts_tensor - ts_tensor[2]) for ts_tensor in ts_tensor_list
        ]
        X.extend(input_tensor_list)
        ts.extend(ts_tensor_list)

    y = [tensor.squeeze() for tensor in label_data_normalized]
    return X, y, ts

# %% ../../nbs/Model/01_model.ipynb 23
def get_train_test_split(
    X_ss, y_mm, ts, l_event_id, l_match_id, l_player_id, train_size=0.912, shuffle=False
):
    "Get train and test split"
    train_size = int((len(X_ss) / 22) * train_size) * 22
    (
        X_train,
        X_test,
        y_train,
        y_test,
        ts_train,
        ts_test,
        event_ids_train,
        event_ids_test,
        match_ids_train,
        match_ids_test,
        player_ids_train,
        player_ids_test,
    ) = train_test_split(
        X_ss,
        y_mm,
        ts,
        l_event_id,
        l_match_id,
        l_player_id,
        random_state=42,
        shuffle=shuffle,
        train_size=train_size,
    )

    events_ids = [event_ids_train, event_ids_test]
    match_ids = [match_ids_train, match_ids_test]
    player_ids = [player_ids_train, player_ids_test]
    return (
        tuple(X_train),
        tuple(X_test),
        torch.tensor(np.array(y_train)),
        torch.tensor(np.array(y_test)),
        tuple(ts_train),
        tuple(ts_test),
        events_ids,
        match_ids,
        player_ids,
    )

# %% ../../nbs/Model/01_model.ipynb 27
class series_data(Dataset):
    "Convert into chunks of 22 players and sequences of 5 with all features"

    def __init__(self, x, y, t, feature_num):
        self.x = torch.stack(x).reshape(int(len(x) / 22), 22, 5, feature_num)
        self.y = y.clone().detach().float().reshape(int(len(x) / 22), 22, 2)
        self.t = torch.stack(t).reshape(int(len(x) / 22), 22, 5)
        self.len = int(len(x) / 22)

    def __getitem__(self, idx):
        return self.x[idx], self.y[idx], self.t[idx]

    def __len__(self):
        return self.len
